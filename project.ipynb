{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, ParameterSampler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from nltk.tokenize.casual import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Password:\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge xgboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/hcao/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOU ONLY NEED TO RUN  THIS ONCE(IF YOU HAVEN'T)\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Party</th>\n",
       "      <th>Handle</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>Today, Senate Dems vote to #SaveTheInternet. P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @WinterHavenSun: Winter Haven resident / Al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @NBCLatino: .@RepDarrenSoto noted that Hurr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @NALCABPolicy: Meeting with @RepDarrenSoto ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @Vegalteno: Hurricane season starts on June...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Party         Handle                                              Tweet\n",
       "0  Democrat  RepDarrenSoto  Today, Senate Dems vote to #SaveTheInternet. P...\n",
       "1  Democrat  RepDarrenSoto  RT @WinterHavenSun: Winter Haven resident / Al...\n",
       "2  Democrat  RepDarrenSoto  RT @NBCLatino: .@RepDarrenSoto noted that Hurr...\n",
       "3  Democrat  RepDarrenSoto  RT @NALCABPolicy: Meeting with @RepDarrenSoto ...\n",
       "4  Democrat  RepDarrenSoto  RT @Vegalteno: Hurricane season starts on June..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the raw data and show the data\n",
    "raw_data = pd.read_csv(\"./Data/Raw/ExtractedTweets.csv\")\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Democrat', 'Republican'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.Party.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of             Party         Handle  \\\n",
       "0        Democrat  RepDarrenSoto   \n",
       "1        Democrat  RepDarrenSoto   \n",
       "2        Democrat  RepDarrenSoto   \n",
       "3        Democrat  RepDarrenSoto   \n",
       "4        Democrat  RepDarrenSoto   \n",
       "...           ...            ...   \n",
       "86455  Republican    RepTomPrice   \n",
       "86456  Republican    RepTomPrice   \n",
       "86457  Republican    RepTomPrice   \n",
       "86458  Republican    RepTomPrice   \n",
       "86459  Republican    RepTomPrice   \n",
       "\n",
       "                                                   Tweet  \n",
       "0      Today, Senate Dems vote to #SaveTheInternet. P...  \n",
       "1      RT @WinterHavenSun: Winter Haven resident / Al...  \n",
       "2      RT @NBCLatino: .@RepDarrenSoto noted that Hurr...  \n",
       "3      RT @NALCABPolicy: Meeting with @RepDarrenSoto ...  \n",
       "4      RT @Vegalteno: Hurricane season starts on June...  \n",
       "...                                                  ...  \n",
       "86455  Check out my op-ed on need for End Executive O...  \n",
       "86456  Yesterday, Betty &amp; I had a great time lear...  \n",
       "86457  We are forever grateful for the service and sa...  \n",
       "86458  Happy first day of school @CobbSchools! #CobbB...  \n",
       "86459  #Zika fears realized in Florida. House GOP act...  \n",
       "\n",
       "[86460 rows x 3 columns]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning\n",
    "Before we start to vectorizing the tweets, we firstly need to clean the tweets text\n",
    "\n",
    "- Remove punctuations\n",
    "- Remove special symbols, e.g. @xxx\n",
    "- Remove stop words\n",
    "- stemmming\n",
    "\n",
    "TODO: nltk has a class called TweetTokenizer, poentially can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(t):\n",
    "    t = re.sub('@\\w+','', t)\n",
    "    t = \"\".join([char for char in t if char not in string.punctuation])\n",
    "    t = re.sub('[0-9]+', '', t)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['tweet_no_punc'] = raw_data.Tweet.apply(lambda x: remove_punctuations(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Party</th>\n",
       "      <th>Handle</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>tweet_no_punc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>Today, Senate Dems vote to #SaveTheInternet. P...</td>\n",
       "      <td>Today Senate Dems vote to SaveTheInternet Prou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @WinterHavenSun: Winter Haven resident / Al...</td>\n",
       "      <td>RT  Winter Haven resident  Alta Vista teacher ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @NBCLatino: .@RepDarrenSoto noted that Hurr...</td>\n",
       "      <td>RT   noted that Hurricane Maria has left appro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @NALCABPolicy: Meeting with @RepDarrenSoto ...</td>\n",
       "      <td>RT  Meeting with   Thanks for taking the time ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @Vegalteno: Hurricane season starts on June...</td>\n",
       "      <td>RT  Hurricane season starts on June st Puerto ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @EmgageActionFL: Thank you to all who came ...</td>\n",
       "      <td>RT  Thank you to all who came out to our Orlan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>Hurricane Maria left approx $90 billion in dam...</td>\n",
       "      <td>Hurricane Maria left approx  billion in damage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @Tharryry: I am delighted that @RepDarrenSo...</td>\n",
       "      <td>RT  I am delighted that  will be voting for th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @HispanicCaucus: Trump's anti-immigrant pol...</td>\n",
       "      <td>RT  Trumps antiimmigrant policies are hurting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @RepStephMurphy: Great joining @WeAreUnidos...</td>\n",
       "      <td>RT  Great joining  and  for a roundtable in Or...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Party         Handle                                              Tweet  \\\n",
       "0  Democrat  RepDarrenSoto  Today, Senate Dems vote to #SaveTheInternet. P...   \n",
       "1  Democrat  RepDarrenSoto  RT @WinterHavenSun: Winter Haven resident / Al...   \n",
       "2  Democrat  RepDarrenSoto  RT @NBCLatino: .@RepDarrenSoto noted that Hurr...   \n",
       "3  Democrat  RepDarrenSoto  RT @NALCABPolicy: Meeting with @RepDarrenSoto ...   \n",
       "4  Democrat  RepDarrenSoto  RT @Vegalteno: Hurricane season starts on June...   \n",
       "5  Democrat  RepDarrenSoto  RT @EmgageActionFL: Thank you to all who came ...   \n",
       "6  Democrat  RepDarrenSoto  Hurricane Maria left approx $90 billion in dam...   \n",
       "7  Democrat  RepDarrenSoto  RT @Tharryry: I am delighted that @RepDarrenSo...   \n",
       "8  Democrat  RepDarrenSoto  RT @HispanicCaucus: Trump's anti-immigrant pol...   \n",
       "9  Democrat  RepDarrenSoto  RT @RepStephMurphy: Great joining @WeAreUnidos...   \n",
       "\n",
       "                                       tweet_no_punc  \n",
       "0  Today Senate Dems vote to SaveTheInternet Prou...  \n",
       "1  RT  Winter Haven resident  Alta Vista teacher ...  \n",
       "2  RT   noted that Hurricane Maria has left appro...  \n",
       "3  RT  Meeting with   Thanks for taking the time ...  \n",
       "4  RT  Hurricane season starts on June st Puerto ...  \n",
       "5  RT  Thank you to all who came out to our Orlan...  \n",
       "6  Hurricane Maria left approx  billion in damage...  \n",
       "7  RT  I am delighted that  will be voting for th...  \n",
       "8  RT  Trumps antiimmigrant policies are hurting ...  \n",
       "9  RT  Great joining  and  for a roundtable in Or...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(t):\n",
    "    t = re.split('\\W+', t)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['tokenized'] = raw_data.tweet_no_punc.apply(lambda x: tokenization(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Party</th>\n",
       "      <th>Handle</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>tweet_no_punc</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>Today, Senate Dems vote to #SaveTheInternet. P...</td>\n",
       "      <td>Today Senate Dems vote to SaveTheInternet Prou...</td>\n",
       "      <td>[Today, Senate, Dems, vote, to, SaveTheInterne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @WinterHavenSun: Winter Haven resident / Al...</td>\n",
       "      <td>RT  Winter Haven resident  Alta Vista teacher ...</td>\n",
       "      <td>[RT, Winter, Haven, resident, Alta, Vista, tea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @NBCLatino: .@RepDarrenSoto noted that Hurr...</td>\n",
       "      <td>RT   noted that Hurricane Maria has left appro...</td>\n",
       "      <td>[RT, noted, that, Hurricane, Maria, has, left,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @NALCABPolicy: Meeting with @RepDarrenSoto ...</td>\n",
       "      <td>RT  Meeting with   Thanks for taking the time ...</td>\n",
       "      <td>[RT, Meeting, with, Thanks, for, taking, the, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @Vegalteno: Hurricane season starts on June...</td>\n",
       "      <td>RT  Hurricane season starts on June st Puerto ...</td>\n",
       "      <td>[RT, Hurricane, season, starts, on, June, st, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @EmgageActionFL: Thank you to all who came ...</td>\n",
       "      <td>RT  Thank you to all who came out to our Orlan...</td>\n",
       "      <td>[RT, Thank, you, to, all, who, came, out, to, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>Hurricane Maria left approx $90 billion in dam...</td>\n",
       "      <td>Hurricane Maria left approx  billion in damage...</td>\n",
       "      <td>[Hurricane, Maria, left, approx, billion, in, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @Tharryry: I am delighted that @RepDarrenSo...</td>\n",
       "      <td>RT  I am delighted that  will be voting for th...</td>\n",
       "      <td>[RT, I, am, delighted, that, will, be, voting,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @HispanicCaucus: Trump's anti-immigrant pol...</td>\n",
       "      <td>RT  Trumps antiimmigrant policies are hurting ...</td>\n",
       "      <td>[RT, Trumps, antiimmigrant, policies, are, hur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @RepStephMurphy: Great joining @WeAreUnidos...</td>\n",
       "      <td>RT  Great joining  and  for a roundtable in Or...</td>\n",
       "      <td>[RT, Great, joining, and, for, a, roundtable, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Party         Handle                                              Tweet  \\\n",
       "0  Democrat  RepDarrenSoto  Today, Senate Dems vote to #SaveTheInternet. P...   \n",
       "1  Democrat  RepDarrenSoto  RT @WinterHavenSun: Winter Haven resident / Al...   \n",
       "2  Democrat  RepDarrenSoto  RT @NBCLatino: .@RepDarrenSoto noted that Hurr...   \n",
       "3  Democrat  RepDarrenSoto  RT @NALCABPolicy: Meeting with @RepDarrenSoto ...   \n",
       "4  Democrat  RepDarrenSoto  RT @Vegalteno: Hurricane season starts on June...   \n",
       "5  Democrat  RepDarrenSoto  RT @EmgageActionFL: Thank you to all who came ...   \n",
       "6  Democrat  RepDarrenSoto  Hurricane Maria left approx $90 billion in dam...   \n",
       "7  Democrat  RepDarrenSoto  RT @Tharryry: I am delighted that @RepDarrenSo...   \n",
       "8  Democrat  RepDarrenSoto  RT @HispanicCaucus: Trump's anti-immigrant pol...   \n",
       "9  Democrat  RepDarrenSoto  RT @RepStephMurphy: Great joining @WeAreUnidos...   \n",
       "\n",
       "                                       tweet_no_punc  \\\n",
       "0  Today Senate Dems vote to SaveTheInternet Prou...   \n",
       "1  RT  Winter Haven resident  Alta Vista teacher ...   \n",
       "2  RT   noted that Hurricane Maria has left appro...   \n",
       "3  RT  Meeting with   Thanks for taking the time ...   \n",
       "4  RT  Hurricane season starts on June st Puerto ...   \n",
       "5  RT  Thank you to all who came out to our Orlan...   \n",
       "6  Hurricane Maria left approx  billion in damage...   \n",
       "7  RT  I am delighted that  will be voting for th...   \n",
       "8  RT  Trumps antiimmigrant policies are hurting ...   \n",
       "9  RT  Great joining  and  for a roundtable in Or...   \n",
       "\n",
       "                                           tokenized  \n",
       "0  [Today, Senate, Dems, vote, to, SaveTheInterne...  \n",
       "1  [RT, Winter, Haven, resident, Alta, Vista, tea...  \n",
       "2  [RT, noted, that, Hurricane, Maria, has, left,...  \n",
       "3  [RT, Meeting, with, Thanks, for, taking, the, ...  \n",
       "4  [RT, Hurricane, season, starts, on, June, st, ...  \n",
       "5  [RT, Thank, you, to, all, who, came, out, to, ...  \n",
       "6  [Hurricane, Maria, left, approx, billion, in, ...  \n",
       "7  [RT, I, am, delighted, that, will, be, voting,...  \n",
       "8  [RT, Trumps, antiimmigrant, policies, are, hur...  \n",
       "9  [RT, Great, joining, and, for, a, roundtable, ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(t):\n",
    "    t = [word for word in t if word not in stopword]\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['no_stop_words'] = raw_data.tokenized.apply(lambda x: remove_stop_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Party</th>\n",
       "      <th>Handle</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>tweet_no_punc</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>no_stop_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>Today, Senate Dems vote to #SaveTheInternet. P...</td>\n",
       "      <td>Today Senate Dems vote to SaveTheInternet Prou...</td>\n",
       "      <td>[Today, Senate, Dems, vote, to, SaveTheInterne...</td>\n",
       "      <td>[Today, Senate, Dems, vote, SaveTheInternet, P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @WinterHavenSun: Winter Haven resident / Al...</td>\n",
       "      <td>RT  Winter Haven resident  Alta Vista teacher ...</td>\n",
       "      <td>[RT, Winter, Haven, resident, Alta, Vista, tea...</td>\n",
       "      <td>[RT, Winter, Haven, resident, Alta, Vista, tea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @NBCLatino: .@RepDarrenSoto noted that Hurr...</td>\n",
       "      <td>RT   noted that Hurricane Maria has left appro...</td>\n",
       "      <td>[RT, noted, that, Hurricane, Maria, has, left,...</td>\n",
       "      <td>[RT, noted, Hurricane, Maria, left, approximat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @NALCABPolicy: Meeting with @RepDarrenSoto ...</td>\n",
       "      <td>RT  Meeting with   Thanks for taking the time ...</td>\n",
       "      <td>[RT, Meeting, with, Thanks, for, taking, the, ...</td>\n",
       "      <td>[RT, Meeting, Thanks, taking, time, meet, ED, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @Vegalteno: Hurricane season starts on June...</td>\n",
       "      <td>RT  Hurricane season starts on June st Puerto ...</td>\n",
       "      <td>[RT, Hurricane, season, starts, on, June, st, ...</td>\n",
       "      <td>[RT, Hurricane, season, starts, June, st, Puer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @EmgageActionFL: Thank you to all who came ...</td>\n",
       "      <td>RT  Thank you to all who came out to our Orlan...</td>\n",
       "      <td>[RT, Thank, you, to, all, who, came, out, to, ...</td>\n",
       "      <td>[RT, Thank, came, Orlando, gala, It, successfu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>Hurricane Maria left approx $90 billion in dam...</td>\n",
       "      <td>Hurricane Maria left approx  billion in damage...</td>\n",
       "      <td>[Hurricane, Maria, left, approx, billion, in, ...</td>\n",
       "      <td>[Hurricane, Maria, left, approx, billion, dama...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @Tharryry: I am delighted that @RepDarrenSo...</td>\n",
       "      <td>RT  I am delighted that  will be voting for th...</td>\n",
       "      <td>[RT, I, am, delighted, that, will, be, voting,...</td>\n",
       "      <td>[RT, I, delighted, voting, CRA, overrule, FCC,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @HispanicCaucus: Trump's anti-immigrant pol...</td>\n",
       "      <td>RT  Trumps antiimmigrant policies are hurting ...</td>\n",
       "      <td>[RT, Trumps, antiimmigrant, policies, are, hur...</td>\n",
       "      <td>[RT, Trumps, antiimmigrant, policies, hurting,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @RepStephMurphy: Great joining @WeAreUnidos...</td>\n",
       "      <td>RT  Great joining  and  for a roundtable in Or...</td>\n",
       "      <td>[RT, Great, joining, and, for, a, roundtable, ...</td>\n",
       "      <td>[RT, Great, joining, roundtable, Orlando, fede...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Party         Handle                                              Tweet  \\\n",
       "0  Democrat  RepDarrenSoto  Today, Senate Dems vote to #SaveTheInternet. P...   \n",
       "1  Democrat  RepDarrenSoto  RT @WinterHavenSun: Winter Haven resident / Al...   \n",
       "2  Democrat  RepDarrenSoto  RT @NBCLatino: .@RepDarrenSoto noted that Hurr...   \n",
       "3  Democrat  RepDarrenSoto  RT @NALCABPolicy: Meeting with @RepDarrenSoto ...   \n",
       "4  Democrat  RepDarrenSoto  RT @Vegalteno: Hurricane season starts on June...   \n",
       "5  Democrat  RepDarrenSoto  RT @EmgageActionFL: Thank you to all who came ...   \n",
       "6  Democrat  RepDarrenSoto  Hurricane Maria left approx $90 billion in dam...   \n",
       "7  Democrat  RepDarrenSoto  RT @Tharryry: I am delighted that @RepDarrenSo...   \n",
       "8  Democrat  RepDarrenSoto  RT @HispanicCaucus: Trump's anti-immigrant pol...   \n",
       "9  Democrat  RepDarrenSoto  RT @RepStephMurphy: Great joining @WeAreUnidos...   \n",
       "\n",
       "                                       tweet_no_punc  \\\n",
       "0  Today Senate Dems vote to SaveTheInternet Prou...   \n",
       "1  RT  Winter Haven resident  Alta Vista teacher ...   \n",
       "2  RT   noted that Hurricane Maria has left appro...   \n",
       "3  RT  Meeting with   Thanks for taking the time ...   \n",
       "4  RT  Hurricane season starts on June st Puerto ...   \n",
       "5  RT  Thank you to all who came out to our Orlan...   \n",
       "6  Hurricane Maria left approx  billion in damage...   \n",
       "7  RT  I am delighted that  will be voting for th...   \n",
       "8  RT  Trumps antiimmigrant policies are hurting ...   \n",
       "9  RT  Great joining  and  for a roundtable in Or...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [Today, Senate, Dems, vote, to, SaveTheInterne...   \n",
       "1  [RT, Winter, Haven, resident, Alta, Vista, tea...   \n",
       "2  [RT, noted, that, Hurricane, Maria, has, left,...   \n",
       "3  [RT, Meeting, with, Thanks, for, taking, the, ...   \n",
       "4  [RT, Hurricane, season, starts, on, June, st, ...   \n",
       "5  [RT, Thank, you, to, all, who, came, out, to, ...   \n",
       "6  [Hurricane, Maria, left, approx, billion, in, ...   \n",
       "7  [RT, I, am, delighted, that, will, be, voting,...   \n",
       "8  [RT, Trumps, antiimmigrant, policies, are, hur...   \n",
       "9  [RT, Great, joining, and, for, a, roundtable, ...   \n",
       "\n",
       "                                       no_stop_words  \n",
       "0  [Today, Senate, Dems, vote, SaveTheInternet, P...  \n",
       "1  [RT, Winter, Haven, resident, Alta, Vista, tea...  \n",
       "2  [RT, noted, Hurricane, Maria, left, approximat...  \n",
       "3  [RT, Meeting, Thanks, taking, time, meet, ED, ...  \n",
       "4  [RT, Hurricane, season, starts, June, st, Puer...  \n",
       "5  [RT, Thank, came, Orlando, gala, It, successfu...  \n",
       "6  [Hurricane, Maria, left, approx, billion, dama...  \n",
       "7  [RT, I, delighted, voting, CRA, overrule, FCC,...  \n",
       "8  [RT, Trumps, antiimmigrant, policies, hurting,...  \n",
       "9  [RT, Great, joining, roundtable, Orlando, fede...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(t):\n",
    "    t = [ps.stem(word) for word in t]\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['stemmed'] = raw_data.no_stop_words.apply(lambda x: stemming(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Party</th>\n",
       "      <th>Handle</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>tweet_no_punc</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>no_stop_words</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>Today, Senate Dems vote to #SaveTheInternet. P...</td>\n",
       "      <td>Today Senate Dems vote to SaveTheInternet Prou...</td>\n",
       "      <td>[Today, Senate, Dems, vote, to, SaveTheInterne...</td>\n",
       "      <td>[Today, Senate, Dems, vote, SaveTheInternet, P...</td>\n",
       "      <td>[today, senat, dem, vote, savetheinternet, pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @WinterHavenSun: Winter Haven resident / Al...</td>\n",
       "      <td>RT  Winter Haven resident  Alta Vista teacher ...</td>\n",
       "      <td>[RT, Winter, Haven, resident, Alta, Vista, tea...</td>\n",
       "      <td>[RT, Winter, Haven, resident, Alta, Vista, tea...</td>\n",
       "      <td>[RT, winter, haven, resid, alta, vista, teache...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @NBCLatino: .@RepDarrenSoto noted that Hurr...</td>\n",
       "      <td>RT   noted that Hurricane Maria has left appro...</td>\n",
       "      <td>[RT, noted, that, Hurricane, Maria, has, left,...</td>\n",
       "      <td>[RT, noted, Hurricane, Maria, left, approximat...</td>\n",
       "      <td>[RT, note, hurrican, maria, left, approxim, bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @NALCABPolicy: Meeting with @RepDarrenSoto ...</td>\n",
       "      <td>RT  Meeting with   Thanks for taking the time ...</td>\n",
       "      <td>[RT, Meeting, with, Thanks, for, taking, the, ...</td>\n",
       "      <td>[RT, Meeting, Thanks, taking, time, meet, ED, ...</td>\n",
       "      <td>[RT, meet, thank, take, time, meet, ED, marucc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @Vegalteno: Hurricane season starts on June...</td>\n",
       "      <td>RT  Hurricane season starts on June st Puerto ...</td>\n",
       "      <td>[RT, Hurricane, season, starts, on, June, st, ...</td>\n",
       "      <td>[RT, Hurricane, season, starts, June, st, Puer...</td>\n",
       "      <td>[RT, hurrican, season, start, june, st, puerto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @EmgageActionFL: Thank you to all who came ...</td>\n",
       "      <td>RT  Thank you to all who came out to our Orlan...</td>\n",
       "      <td>[RT, Thank, you, to, all, who, came, out, to, ...</td>\n",
       "      <td>[RT, Thank, came, Orlando, gala, It, successfu...</td>\n",
       "      <td>[RT, thank, came, orlando, gala, It, success, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>Hurricane Maria left approx $90 billion in dam...</td>\n",
       "      <td>Hurricane Maria left approx  billion in damage...</td>\n",
       "      <td>[Hurricane, Maria, left, approx, billion, in, ...</td>\n",
       "      <td>[Hurricane, Maria, left, approx, billion, dama...</td>\n",
       "      <td>[hurrican, maria, left, approx, billion, damag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @Tharryry: I am delighted that @RepDarrenSo...</td>\n",
       "      <td>RT  I am delighted that  will be voting for th...</td>\n",
       "      <td>[RT, I, am, delighted, that, will, be, voting,...</td>\n",
       "      <td>[RT, I, delighted, voting, CRA, overrule, FCC,...</td>\n",
       "      <td>[RT, I, delight, vote, cra, overrul, fcc, save...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @HispanicCaucus: Trump's anti-immigrant pol...</td>\n",
       "      <td>RT  Trumps antiimmigrant policies are hurting ...</td>\n",
       "      <td>[RT, Trumps, antiimmigrant, policies, are, hur...</td>\n",
       "      <td>[RT, Trumps, antiimmigrant, policies, hurting,...</td>\n",
       "      <td>[RT, trump, antiimmigr, polici, hurt, small, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @RepStephMurphy: Great joining @WeAreUnidos...</td>\n",
       "      <td>RT  Great joining  and  for a roundtable in Or...</td>\n",
       "      <td>[RT, Great, joining, and, for, a, roundtable, ...</td>\n",
       "      <td>[RT, Great, joining, roundtable, Orlando, fede...</td>\n",
       "      <td>[RT, great, join, roundtabl, orlando, feder, i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Party         Handle                                              Tweet  \\\n",
       "0  Democrat  RepDarrenSoto  Today, Senate Dems vote to #SaveTheInternet. P...   \n",
       "1  Democrat  RepDarrenSoto  RT @WinterHavenSun: Winter Haven resident / Al...   \n",
       "2  Democrat  RepDarrenSoto  RT @NBCLatino: .@RepDarrenSoto noted that Hurr...   \n",
       "3  Democrat  RepDarrenSoto  RT @NALCABPolicy: Meeting with @RepDarrenSoto ...   \n",
       "4  Democrat  RepDarrenSoto  RT @Vegalteno: Hurricane season starts on June...   \n",
       "5  Democrat  RepDarrenSoto  RT @EmgageActionFL: Thank you to all who came ...   \n",
       "6  Democrat  RepDarrenSoto  Hurricane Maria left approx $90 billion in dam...   \n",
       "7  Democrat  RepDarrenSoto  RT @Tharryry: I am delighted that @RepDarrenSo...   \n",
       "8  Democrat  RepDarrenSoto  RT @HispanicCaucus: Trump's anti-immigrant pol...   \n",
       "9  Democrat  RepDarrenSoto  RT @RepStephMurphy: Great joining @WeAreUnidos...   \n",
       "\n",
       "                                       tweet_no_punc  \\\n",
       "0  Today Senate Dems vote to SaveTheInternet Prou...   \n",
       "1  RT  Winter Haven resident  Alta Vista teacher ...   \n",
       "2  RT   noted that Hurricane Maria has left appro...   \n",
       "3  RT  Meeting with   Thanks for taking the time ...   \n",
       "4  RT  Hurricane season starts on June st Puerto ...   \n",
       "5  RT  Thank you to all who came out to our Orlan...   \n",
       "6  Hurricane Maria left approx  billion in damage...   \n",
       "7  RT  I am delighted that  will be voting for th...   \n",
       "8  RT  Trumps antiimmigrant policies are hurting ...   \n",
       "9  RT  Great joining  and  for a roundtable in Or...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [Today, Senate, Dems, vote, to, SaveTheInterne...   \n",
       "1  [RT, Winter, Haven, resident, Alta, Vista, tea...   \n",
       "2  [RT, noted, that, Hurricane, Maria, has, left,...   \n",
       "3  [RT, Meeting, with, Thanks, for, taking, the, ...   \n",
       "4  [RT, Hurricane, season, starts, on, June, st, ...   \n",
       "5  [RT, Thank, you, to, all, who, came, out, to, ...   \n",
       "6  [Hurricane, Maria, left, approx, billion, in, ...   \n",
       "7  [RT, I, am, delighted, that, will, be, voting,...   \n",
       "8  [RT, Trumps, antiimmigrant, policies, are, hur...   \n",
       "9  [RT, Great, joining, and, for, a, roundtable, ...   \n",
       "\n",
       "                                       no_stop_words  \\\n",
       "0  [Today, Senate, Dems, vote, SaveTheInternet, P...   \n",
       "1  [RT, Winter, Haven, resident, Alta, Vista, tea...   \n",
       "2  [RT, noted, Hurricane, Maria, left, approximat...   \n",
       "3  [RT, Meeting, Thanks, taking, time, meet, ED, ...   \n",
       "4  [RT, Hurricane, season, starts, June, st, Puer...   \n",
       "5  [RT, Thank, came, Orlando, gala, It, successfu...   \n",
       "6  [Hurricane, Maria, left, approx, billion, dama...   \n",
       "7  [RT, I, delighted, voting, CRA, overrule, FCC,...   \n",
       "8  [RT, Trumps, antiimmigrant, policies, hurting,...   \n",
       "9  [RT, Great, joining, roundtable, Orlando, fede...   \n",
       "\n",
       "                                             stemmed  \n",
       "0  [today, senat, dem, vote, savetheinternet, pro...  \n",
       "1  [RT, winter, haven, resid, alta, vista, teache...  \n",
       "2  [RT, note, hurrican, maria, left, approxim, bi...  \n",
       "3  [RT, meet, thank, take, time, meet, ED, marucc...  \n",
       "4  [RT, hurrican, season, start, june, st, puerto...  \n",
       "5  [RT, thank, came, orlando, gala, It, success, ...  \n",
       "6  [hurrican, maria, left, approx, billion, damag...  \n",
       "7  [RT, I, delight, vote, cra, overrul, fcc, save...  \n",
       "8  [RT, trump, antiimmigr, polici, hurt, small, b...  \n",
       "9  [RT, great, join, roundtabl, orlando, feder, i...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no need if already stemed, but we can see which one works better tho\n",
    "def lemmatizer(t):\n",
    "    t = [wn.lemmatize(w) for w in t]\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we clean our existing raw data table\n",
    "df = raw_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Party</th>\n",
       "      <th>Handle</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>Today, Senate Dems vote to #SaveTheInternet. P...</td>\n",
       "      <td>[today, senat, dem, vote, savetheinternet, pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @WinterHavenSun: Winter Haven resident / Al...</td>\n",
       "      <td>[RT, winter, haven, resid, alta, vista, teache...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @NBCLatino: .@RepDarrenSoto noted that Hurr...</td>\n",
       "      <td>[RT, note, hurrican, maria, left, approxim, bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @NALCABPolicy: Meeting with @RepDarrenSoto ...</td>\n",
       "      <td>[RT, meet, thank, take, time, meet, ED, marucc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @Vegalteno: Hurricane season starts on June...</td>\n",
       "      <td>[RT, hurrican, season, start, june, st, puerto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86455</th>\n",
       "      <td>Republican</td>\n",
       "      <td>RepTomPrice</td>\n",
       "      <td>Check out my op-ed on need for End Executive O...</td>\n",
       "      <td>[check, ope, need, end, execut, overreach, act...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86456</th>\n",
       "      <td>Republican</td>\n",
       "      <td>RepTomPrice</td>\n",
       "      <td>Yesterday, Betty &amp;amp; I had a great time lear...</td>\n",
       "      <td>[yesterday, betti, amp, I, great, time, learn,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86457</th>\n",
       "      <td>Republican</td>\n",
       "      <td>RepTomPrice</td>\n",
       "      <td>We are forever grateful for the service and sa...</td>\n",
       "      <td>[We, forev, grate, servic, sacrific, major, ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86458</th>\n",
       "      <td>Republican</td>\n",
       "      <td>RepTomPrice</td>\n",
       "      <td>Happy first day of school @CobbSchools! #CobbB...</td>\n",
       "      <td>[happi, first, day, school, cobbbacktoschool]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86459</th>\n",
       "      <td>Republican</td>\n",
       "      <td>RepTomPrice</td>\n",
       "      <td>#Zika fears realized in Florida. House GOP act...</td>\n",
       "      <td>[zika, fear, realiz, florida, hous, gop, act, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86460 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Party         Handle  \\\n",
       "0        Democrat  RepDarrenSoto   \n",
       "1        Democrat  RepDarrenSoto   \n",
       "2        Democrat  RepDarrenSoto   \n",
       "3        Democrat  RepDarrenSoto   \n",
       "4        Democrat  RepDarrenSoto   \n",
       "...           ...            ...   \n",
       "86455  Republican    RepTomPrice   \n",
       "86456  Republican    RepTomPrice   \n",
       "86457  Republican    RepTomPrice   \n",
       "86458  Republican    RepTomPrice   \n",
       "86459  Republican    RepTomPrice   \n",
       "\n",
       "                                                   Tweet  \\\n",
       "0      Today, Senate Dems vote to #SaveTheInternet. P...   \n",
       "1      RT @WinterHavenSun: Winter Haven resident / Al...   \n",
       "2      RT @NBCLatino: .@RepDarrenSoto noted that Hurr...   \n",
       "3      RT @NALCABPolicy: Meeting with @RepDarrenSoto ...   \n",
       "4      RT @Vegalteno: Hurricane season starts on June...   \n",
       "...                                                  ...   \n",
       "86455  Check out my op-ed on need for End Executive O...   \n",
       "86456  Yesterday, Betty &amp; I had a great time lear...   \n",
       "86457  We are forever grateful for the service and sa...   \n",
       "86458  Happy first day of school @CobbSchools! #CobbB...   \n",
       "86459  #Zika fears realized in Florida. House GOP act...   \n",
       "\n",
       "                                                 stemmed  \n",
       "0      [today, senat, dem, vote, savetheinternet, pro...  \n",
       "1      [RT, winter, haven, resid, alta, vista, teache...  \n",
       "2      [RT, note, hurrican, maria, left, approxim, bi...  \n",
       "3      [RT, meet, thank, take, time, meet, ED, marucc...  \n",
       "4      [RT, hurrican, season, start, june, st, puerto...  \n",
       "...                                                  ...  \n",
       "86455  [check, ope, need, end, execut, overreach, act...  \n",
       "86456  [yesterday, betti, amp, I, great, time, learn,...  \n",
       "86457  [We, forev, grate, servic, sacrific, major, ba...  \n",
       "86458      [happi, first, day, school, cobbbacktoschool]  \n",
       "86459  [zika, fear, realiz, florida, hous, gop, act, ...  \n",
       "\n",
       "[86460 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['tweet_no_punc', 'tokenized', 'no_stop_words'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Twitter's political affilication\n",
    "This task focus on individual tweet's political affilication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.Tweet,df.Party, stratify=df.Party, test_size = 0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TweetTokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-257457db5948>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTweetTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduce_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'TweetTokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer = TweetTokenizer(reduce_len=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14800    The Senate Judiciary, in its limited #TrumpRus...\n",
       "803      If youâ€™re reading this, remember to #ThankATea...\n",
       "42239    RT @WRHI: U.S. Representative Ralph Norman joi...\n",
       "24371    RT @HRC: @USRepKeating Congrats on 100% on @HR...\n",
       "71348    Congrats to @RepLoudermilk on House passage of...\n",
       "56256    RT @FoxNews: .@RepDougCollins on the Russia in...\n",
       "78781    RT @hughhewitt: The #SchumerShutdown isnâ€™t pla...\n",
       "35298    Bipartisanship is often applauded, but seldom ...\n",
       "52882    Today, the House of Representatives honors a p...\n",
       "45073    Great visit, thanks @HartzellProp! https://t.c...\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_pipleline = Pipeline([\n",
    "    ('vectorize', TfidfVectorizer(tokenizer=tokenizer.tokenize)),\n",
    "    ('classifier', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorize',\n",
       "                 TfidfVectorizer(tokenizer=<bound method TweetTokenizer.tokenize of <nltk.tokenize.casual.TweetTokenizer object at 0x7fb143f73160>>)),\n",
       "                ('classifier', MultinomialNB())])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_pipleline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = nb_pipleline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7991\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {}'.format(str(round(accuracy_score(y_test, preds), 4))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem\n",
    "Although the result looks promising, the TweetTokenizer did not remove the user ID. User ID directly reveal the information of the party afflication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection (Which model to use)\n",
    "It seems that our model works pretty well already! Then let's try some model selection. Which model works the best for this task?\n",
    "Here is a list of algorithms that I want to try:\n",
    "\n",
    "- Esemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "gboost_cl = GradientBoostingClassifier(random_state=123, max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "gboost_pipe = Pipeline([\n",
    "    ('vectorize', TfidfVectorizer(tokenizer=tokenizer.tokenize)),\n",
    "    ('classifier', gboost_cl)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorize',\n",
       "                 TfidfVectorizer(tokenizer=<bound method TweetTokenizer.tokenize of <nltk.tokenize.casual.TweetTokenizer object at 0x7fb143f73160>>)),\n",
       "                ('classifier',\n",
       "                 GradientBoostingClassifier(max_depth=10, random_state=123))])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gboost_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6945\n"
     ]
    }
   ],
   "source": [
    "preds_gboost = gboost_pipe.predict(X_test)\n",
    "print('Accuracy: {}'.format(str(round(accuracy_score(y_test, preds_gboost), 4))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems the gradient boost method doesn't do very good, we should try grid search to find better set of HP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try some SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_cl = SVC(gamma='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_pipe = Pipeline([\n",
    "    ('vectorize', TfidfVectorizer(tokenizer=tokenizer.tokenize)),\n",
    "    ('classifier', svm_cl)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "The TF-IDF vectorizer is not fitted",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-b9c5657350ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreds_svm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_svm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents, copy)\u001b[0m\n\u001b[1;32m   1870\u001b[0m             \u001b[0mTf\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0midf\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mweighted\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mterm\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1871\u001b[0m         \"\"\"\n\u001b[0;32m-> 1872\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'The TF-IDF vectorizer is not fitted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1874\u001b[0m         \u001b[0;31m# FIXME Remove copy parameter support in 0.24\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: The TF-IDF vectorizer is not fitted"
     ]
    }
   ],
   "source": [
    "preds_svm = svm_pipe.predict(X_test)\n",
    "print('Accuracy: {}'.format(str(round(accuracy_score(y_test, preds_svm), 4))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pipe = Pipeline([\n",
    "    ('vectorize', TfidfVectorizer(tokenizer=tokenizer.tokenize)),\n",
    "    ('classifier', XGBClassifier(max_depth=20, n_estimators=300, learning_rate=0.1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorize',\n",
       "                 TfidfVectorizer(tokenizer=<bound method TweetTokenizer.tokenize of <nltk.tokenize.casual.TweetTokenizer object at 0x7ff677afe6d8>>)),\n",
       "                ('classifier', XGBClassifier(max_depth=20, n_estimators=300))])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_preds = xgb_pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7385\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {}'.format(str(round(accuracy_score(y_test, xgb_preds), 4))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection (Which parameter to use?)\n",
    "Based on our results above, we eventually decide to use multinomial naive bayes and xgboost as our final models. Before evaluating them, we need to tune them first. We decide to user grid serch to find the best possible hyperparameters for both of them. Then we will use cross validation to evaluate the performance. \n",
    "\n",
    "## Multinomial Naive Bayes\n",
    "for naive bayes, we have the following hyperparamters:\n",
    "- alpha\n",
    "- fit_prior\n",
    "- class_prior\n",
    "\n",
    "However, we may only care about alpha in this case. Since we don't have much options to try, we can use grid search.\n",
    "\n",
    "## xgboost\n",
    "for xgboost, we have way more hyperparamters than naive bayes. However, we mainly focus on the following:\n",
    "- max_depth\n",
    "- min_child_weight\n",
    "- eta\n",
    "- subsample\n",
    "- colsample_by_tree\n",
    "\n",
    "We have many hyperparameters to train therefore we use randomnized search to save time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial NB pipeline\n",
    "nb_params = [{'classifier__alpha': [3,2,1,0.1, 0.01, 0.001, 0.0001, 0.00001]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(estimator=nb_pipleline, param_grid=nb_params, refit=True, cv=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('vectorize',\n",
       "                                        TfidfVectorizer(tokenizer=<bound method TweetTokenizer.tokenize of <nltk.tokenize.casual.TweetTokenizer object at 0x7ff677afe6d8>>)),\n",
       "                                       ('classifier', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'classifier__alpha': [3, 2, 1, 0.1, 0.01, 0.001,\n",
       "                                                0.0001, 1e-05]}])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 81.08%\n",
      "Best Params: {'classifier__alpha': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print('Best Accuracy: %.2f%%' % (gs.best_score_*100))\n",
    "print('Best Params:', gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77903078, 0.78773426, 0.79807133, 0.81079409, 0.80564723,\n",
       "       0.8017871 , 0.80019676, 0.79944497])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 8 artists>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(['3','2','1','0.1', '0.01', '0.001', '0.0001', '0.00001'],gs.cv_results_['mean_test_score'],align='center', alpha=0.5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgboost pipeline\n",
    "import scipy.stats\n",
    "\n",
    "d = {'classifier__max_depth':[5,6,7,8,9,10],\n",
    "     'min_child_weight': scipy.stats.uniform(loc=0, scale=10),\n",
    "     'eta': scipy.stats.uniform(loc=0, scale=2)}\n",
    "\n",
    "ps = ParameterSampler(param_distributions=d,\n",
    "                      n_iter=10, \n",
    "                      random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.model_selection._search.ParameterSampler at 0x7ff66905aef0>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = RandomizedSearchCV(estimator=xgb_pipe, param_distributions=d, n_iter=20, cv=4, refit=True, random_state=123, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/hcao/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-90-38f8c562b06d>\", line 1, in <module>\n",
      "    rs.fit(X_train, y_train)\n",
      "  File \"/Users/hcao/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/hcao/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\", line 736, in fit\n",
      "    self._run_search(evaluate_candidates)\n",
      "  File \"/Users/hcao/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\", line 1531, in _run_search\n",
      "    random_state=self.random_state))\n",
      "  File \"/Users/hcao/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\", line 715, in evaluate_candidates\n",
      "    cv.split(X, y, groups)))\n",
      "  File \"/Users/hcao/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 1042, in __call__\n",
      "    self.retrieve()\n",
      "  File \"/Users/hcao/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 921, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"/Users/hcao/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 542, in wrap_future_result\n",
      "    return future.result(timeout=timeout)\n",
      "  File \"/Users/hcao/anaconda3/lib/python3.7/concurrent/futures/_base.py\", line 427, in result\n",
      "    self._condition.wait(timeout)\n",
      "  File \"/Users/hcao/anaconda3/lib/python3.7/threading.py\", line 296, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hcao/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2018, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hcao/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/hcao/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/hcao/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/hcao/anaconda3/lib/python3.7/inspect.py\", line 1500, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/hcao/anaconda3/lib/python3.7/inspect.py\", line 1458, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/hcao/anaconda3/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/hcao/anaconda3/lib/python3.7/inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "TODO:\n",
    "- confusion matrics\n",
    "- McNemar\n",
    "- .632+\n",
    "- Randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
